{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T19:14:50.284975Z","iopub.status.busy":"2022-12-30T19:14:50.284151Z","iopub.status.idle":"2022-12-30T19:14:52.495326Z","shell.execute_reply":"2022-12-30T19:14:52.494368Z","shell.execute_reply.started":"2022-12-30T19:14:50.284884Z"},"id":"nisf8AY7jy8e","trusted":true},"outputs":[],"source":["import os\n","import numpy as np\n","import glob\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.datasets import MNIST\n","from PIL import Image\n","from torch.utils.data import Subset\n","from torch.optim import Optimizer\n","from sklearn.model_selection import train_test_split\n","from torchvision.models import vgg16\n","from tqdm import tqdm\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T19:20:22.718276Z","iopub.status.busy":"2022-12-30T19:20:22.717907Z","iopub.status.idle":"2022-12-30T19:20:22.812377Z","shell.execute_reply":"2022-12-30T19:20:22.811205Z","shell.execute_reply.started":"2022-12-30T19:20:22.718243Z"},"trusted":true},"outputs":[],"source":["SEED = 42 # For reproducibility\n","\n","# Image transformer\n","img_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.5], [0.5])\n","])\n","# Batch size for training and testing\n","TRAIN_BATCHSIZE = 128\n","TEST_BATCHSIZE = 64\n","\n","# Download dataset\n","train_dataset = MNIST('./data', transform=img_transform, download=True, train=True)\n","test_dataset = MNIST('./data', transform=img_transform, download=True, train=False)\n","\n","# Dataset length\n","num_train = len(train_dataset)\n","num_test = len(test_dataset)\n","print(f\"Num. training samples: {num_train}\")\n","print(f\"Num. test samples:     {num_test}\")\n","\n","# Fraction of the original train set that we want to use as validation set\n","val_frac = 0.2\n","# Number of samples of the validation set\n","num_val = int(num_train * val_frac) \n","num_train = num_train - num_val\n","\n","print(f\"{num_train} samples used as train dataset\")\n","print(f\"{num_val}  samples used as val dataset\")\n","\n","# Split train_dataset into training and validation\n","train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [num_train, num_val], \n","                                                           generator=torch.Generator().manual_seed(SEED))\n","# Build dataloaders\n","train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCHSIZE, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=TEST_BATCHSIZE, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=TEST_BATCHSIZE, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T19:20:43.407556Z","iopub.status.busy":"2022-12-30T19:20:43.407154Z","iopub.status.idle":"2022-12-30T19:20:43.426169Z","shell.execute_reply":"2022-12-30T19:20:43.424942Z","shell.execute_reply.started":"2022-12-30T19:20:43.407523Z"},"trusted":true},"outputs":[],"source":["class VGGBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, batch_norm=False):\n","        super().__init__()\n","        conv2_params = {\n","            'kernel_size': (3, 3),\n","            'stride'     : (1, 1),\n","            'padding'   : 1\n","        }\n","        noop = lambda x : x\n","\n","        self._batch_norm = batch_norm\n","\n","        self.conv1 = nn.Conv2d(in_channels=in_channels,out_channels=out_channels , **conv2_params)\n","        self.bn1 = nn.BatchNorm2d(out_channels) if batch_norm else noop\n","\n","        self.conv2 = nn.Conv2d(in_channels=out_channels,out_channels=out_channels, **conv2_params)\n","        self.bn2 = nn.BatchNorm2d(out_channels) if batch_norm else noop\n","\n","        self.max_pooling = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n","\n","    @property\n","    def batch_norm(self):\n","        return self._batch_norm\n","\n","    def forward(self,x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = F.relu(x)\n","\n","        x = self.conv2(x)\n","        x = self.bn2(x)\n","        x = F.relu(x)\n","\n","        x = self.max_pooling(x)\n","        return x\n","    \n","class VGG16(nn.Module):\n","    def __init__(self, config):\n","        super(VGG16, self).__init__()\n","        self.config = config\n","        self.in_channels, self.in_width, self.in_height = config.input_size\n","\n","        self.block_1 = VGGBlock(self.in_channels, 64, batch_norm=config.batch_norm)\n","        self.block_2 = VGGBlock(64, 128,batch_norm=config.batch_norm)\n","        self.block_3 = VGGBlock(128, 256,batch_norm=config.batch_norm)\n","        self.block_4 = VGGBlock(256,512,batch_norm=config.batch_norm)\n","\n","        self.classifier = nn.Sequential(\n","                nn.Linear(512, 256),\n","                nn.ReLU(True),\n","                nn.Dropout(p=0.65),\n","                nn.Linear(256, 128),\n","                nn.ReLU(True),\n","                nn.Dropout(p=0.65),\n","                nn.Linear(128, config.num_classes) \n","            )\n","\n","    @property\n","    def input_size(self):\n","        return self.in_channels,self.in_width,self.in_height\n","\n","    def forward(self, x):\n","\n","        x = self.block_1(x)\n","        x = self.block_2(x)\n","        x = self.block_3(x)\n","        x = self.block_4(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.classifier(x)\n","\n","        return x\n","    \n","    @staticmethod\n","    def _init_model_with_state_dict(state):\n","        model = VGG16(state['model_config'])\n","        model.load_state_dict(state['model_state_dict'])\n","        return model\n","    \n","    @classmethod\n","    def load(cls, path):\n","        r\"\"\"\n","        Loads a model with data fields and pretrained model parameters.\n","        Args:\n","            path (str):\n","                - a string with the shortcut name of a pretrained learner\n","                  to load from .pt file.\n","        Examples:\n","            >>> # model = VGG16.load('./tmp/resources/<model_name>.pt')\n","        \"\"\"\n","        if os.path.exists(path):\n","            state = torch.load(path)\n","        else:\n","            raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), path)\n","        model = cls._init_model_with_state_dict(state)\n","        return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T19:20:43.759944Z","iopub.status.busy":"2022-12-30T19:20:43.759620Z","iopub.status.idle":"2022-12-30T19:20:43.778105Z","shell.execute_reply":"2022-12-30T19:20:43.777229Z","shell.execute_reply.started":"2022-12-30T19:20:43.759914Z"},"trusted":true},"outputs":[],"source":["\n","class AdamOptimizer(Optimizer):\n","    \"\"\"\n","    implements ADAM Algorithm, as a preceding step.\n","    \"\"\"\n","    def __init__(self, params, lr=1e-3, betas=(0.9, 0.99), eps=1e-8, weight_decay=0):\n","        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n","        super(AdamOptimizer, self).__init__(params, defaults)\n","        \n","    def step(self):\n","        import math\n","        \"\"\"\n","        Performs a single optimization step.\n","        \"\"\"\n","        loss = None\n","        for group in self.param_groups:\n","\n","            for p in group['params']:\n","                grad = p.grad.data\n","                state = self.state[p]\n","\n","                # State initialization\n","                if len(state) == 0:\n","                    state['step'] = 0\n","                    # Momentum (Exponential MA of gradients)\n","                    state['exp_avg'] = torch.zeros_like(p.data)\n","                    #print(p.data.size())\n","                    # RMS Prop componenet. (Exponential MA of squared gradients). Denominator.\n","                    state['exp_avg_sq'] = torch.zeros_like(p.data)\n","                    \n","                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n","\n","                b1, b2 = group['betas']\n","                state['step'] += 1\n","                \n","                # L2 penalty. Gotta add to Gradient as well.\n","                if group['weight_decay'] != 0:\n","                    grad = grad.add(group['weight_decay'], p.data)\n","\n","                # Momentum\n","                exp_avg = torch.mul(exp_avg, b1) + (1 - b1)*grad\n","                # RMS\n","                exp_avg_sq = torch.mul(exp_avg_sq, b2) + (1-b2)*(grad*grad)\n","                \n","                denom = exp_avg_sq.sqrt() + group['eps']\n","\n","                bias_correction1 = 1 / (1 - b1 ** state['step'])\n","                bias_correction2 = 1 / (1 - b2 ** state['step'])\n","                \n","                adapted_learning_rate = group['lr'] * bias_correction1 / math.sqrt(bias_correction2)\n","\n","                p.data = p.data - adapted_learning_rate * exp_avg / denom \n","\n","        return loss\n","\n","class SgdOptimizer(Optimizer):\n","    \"\"\"Implements SGD Algorithm\n","    The Nesterov version can be performed by choosing input argument\n","    \"\"\"\n","    def __init__(self, \n","        params, \n","        lr=1e-3, \n","        momentum=0, \n","        dampening=0,\n","        weight_decay=0, \n","        nesterov=False):\n","\n","        defaults = dict(lr=lr, momentum=momentum,\n","                        dampening=dampening,\n","                        weight_decay=weight_decay, \n","                        nesterov=nesterov)\n","\n","        super(SgdOptimizer, self).__init__(params, defaults)\n","\n","    def step(self):\n","        loss = None\n","        for group in self.param_groups:\n","            weight_decay = group['weight_decay']\n","            momentum = group['momentum']\n","            dampening = group['dampening']\n","            nesterov = group['nesterov']\n","\n","            for p in group['params']:\n","                if p.grad is None:\n","                    continue\n","                d_p = p.grad.data\n","                if weight_decay != 0:\n","                    d_p.add_(weight_decay, p.data)\n","                if momentum != 0:\n","                    param_state = self.state[p]\n","                    if 'momentum_buffer' not in param_state:\n","                        buf = param_state['momentum_buffer'] = torch.zeros_like(p.data)\n","                        buf.mul_(momentum).add_(d_p)\n","                    else:\n","                        buf = param_state['momentum_buffer']\n","                        buf.mul_(momentum).add_(1 - dampening, d_p)\n","                    if nesterov:\n","                        d_p = d_p.add(momentum, buf)\n","                    else:\n","                        d_p = buf\n","\n","                p.data.add_(-group['lr'], d_p)\n","\n","        return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T19:23:31.989022Z","iopub.status.busy":"2022-12-30T19:23:31.988647Z","iopub.status.idle":"2022-12-30T19:23:31.996044Z","shell.execute_reply":"2022-12-30T19:23:31.994871Z","shell.execute_reply.started":"2022-12-30T19:23:31.988990Z"},"trusted":true},"outputs":[],"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","class TrainingArgs:\n","    def __init__(self):\n","        self.lr = 1e-3\n","        self.num_epochs = 50\n","        self.input_size = (1,28,28)\n","        self.num_classes = 10\n","        self.optimizer = 'sgd'\n","        self.batch_norm = True\n","        self.nesterov = True\n","        self.momentum = 0.96\n","        self.weight_decay = 1e-5\n","        \n","args = TrainingArgs()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T19:23:32.289113Z","iopub.status.busy":"2022-12-30T19:23:32.288833Z","iopub.status.idle":"2022-12-30T19:23:32.348942Z","shell.execute_reply":"2022-12-30T19:23:32.347968Z","shell.execute_reply.started":"2022-12-30T19:23:32.289087Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = VGG16(args).to(device)\n","\n","print(\">> Model's Architecture: \")\n","print(model)\n","print(f\">> Total parameters: {count_parameters(model)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T19:23:38.053414Z","iopub.status.busy":"2022-12-30T19:23:38.052969Z","iopub.status.idle":"2022-12-30T19:23:38.060841Z","shell.execute_reply":"2022-12-30T19:23:38.059718Z","shell.execute_reply.started":"2022-12-30T19:23:38.053374Z"},"id":"HU_g5HWK6Eej","trusted":true},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","\n","if args.optimizer == 'adam':\n","    optim = AdamOptimizer(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n","else:\n","    optim = SgdOptimizer(model.parameters(), lr=args.lr, \n","                         weight_decay=args.weight_decay, \n","                         momentum=args.momentum, nesterov=args.nesterov)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T19:23:43.816690Z","iopub.status.busy":"2022-12-30T19:23:43.815255Z","iopub.status.idle":"2022-12-30T19:26:18.063596Z","shell.execute_reply":"2022-12-30T19:26:18.062239Z","shell.execute_reply.started":"2022-12-30T19:23:43.816648Z"},"id":"E1PPwe5a6ZVt","outputId":"209da9ae-2be4-4a72-eb3d-cabc5c8b003d","trusted":true},"outputs":[],"source":["history = {'acc': {'train': [], 'val': []}, \n","    'loss': {'train': [], 'val': []}}\n","min_val_loss = np.inf\n","\n","for epoch in range(args.num_epochs):\n","    # Training\n","    train_iterator = tqdm(train_loader, leave=True)\n","    running_train_loss = 0.0\n","    running_train_acc = 0.0\n","    model.train()\n","    for i, (images, labels) in enumerate(train_iterator):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        train_acc = ((outputs.argmax(dim=1) == labels).float().mean())        \n","        # Backward pass\n","        optim.zero_grad()\n","        loss.backward()\n","        optim.step()\n","\n","        # Gather training loss and acc\n","        running_train_loss += loss.item()\n","        running_train_acc += train_acc.item()\n","        \n","        train_iterator.set_description('(Train) Epoch [{}/{}]'.format(epoch, args.num_epochs))\n","        train_iterator.set_postfix(train_loss=loss.item(), train_acc=train_acc.item())\n","\n","    epoch_train_loss = running_train_loss/len(train_loader)\n","    epoch_train_acc = running_train_acc/len(train_loader)\n","\n","    history['acc']['train'].append(epoch_train_acc)\n","    history['loss']['train'].append(epoch_train_loss)\n","    \n","    # Evaluation\n","    val_iterator = tqdm(val_loader, leave=True)\n","    running_val_loss = 0.0\n","    running_val_acc = 0.0\n","    model.eval()\n","    for vidx, (val_images, val_labels) in enumerate(val_iterator):\n","        with torch.no_grad():\n","            val_images = val_images.to(device)\n","            val_labels = val_labels.to(device)\n","\n","            val_outputs = model(val_images)\n","            val_loss = criterion(val_outputs, val_labels)\n","            val_acc = ((val_outputs.argmax(dim=1) == val_labels).float().mean())\n","\n","            running_val_loss += val_loss.item()\n","            running_val_acc += val_acc.item()\n","            \n","            val_iterator.set_description('(Val) Epoch [{}/{}]'.format(epoch, args.num_epochs))\n","            val_iterator.set_postfix(val_loss=val_loss.item(), val_acc=val_acc.item())\n","            \n","    epoch_val_acc = running_val_acc/len(val_loader)\n","    epoch_val_loss = running_val_loss/len(val_loader)\n","\n","    history['acc']['val'].append(epoch_val_acc)\n","    history['loss']['val'].append(epoch_val_loss)\n","    \n","    print(f'>> Epoch [{epoch+1}/{args.num_epochs}]:\\tTrain loss = {epoch_train_loss:.5f} | Val loss = {epoch_val_loss:.5f},\\\n","                \\t Train Acc = {epoch_train_acc:.5f} | Val Acc = {epoch_val_acc:.5f}')\n","    if epoch_val_loss < min_val_loss:\n","        min_val_loss = epoch_val_loss\n","        print(\">> Saving The Model Checkpoint\")\n","        torch.save(\n","            {\n","                'model_config': model.config,\n","                'model_state_dict': model.state_dict(),\n","                'optim_state_dict': optim.state_dict(),\n","                'history': history\n","            }, './vgg16-sgd-nesterov-mnist.pt'\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T09:52:33.678847Z","iopub.status.busy":"2022-12-30T09:52:33.678379Z","iopub.status.idle":"2022-12-30T09:52:34.201761Z","shell.execute_reply":"2022-12-30T09:52:34.200903Z","shell.execute_reply.started":"2022-12-30T09:52:33.678810Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","fig, axs = plt.subplots(1,2, figsize=(20,6))\n","\n","axs[0].plot(np.arange(len(history['acc']['train'])), history['acc']['train'])\n","axs[0].plot(np.arange(len(history['acc']['val'])), history['acc']['val'])\n","axs[0].set_title('Model Accuracy', fontsize = 16)\n","axs[0].set_ylabel('Accuracy', fontsize = 14)\n","axs[0].set_xlabel('Epoch', fontsize = 14)\n","axs[0].legend(['train-acc', 'val-acc'], loc='upper left', fontsize = 14)\n","\n","axs[1].plot(np.arange(len(history['loss']['train'])), history['loss']['train'])\n","axs[1].plot(np.arange(len(history['loss']['val'])), history['loss']['val'])\n","axs[1].set_title('Model Loss', fontsize = 16)\n","axs[1].set_ylabel('Loss', fontsize = 14)\n","axs[1].set_xlabel('Epoch', fontsize = 14)\n","axs[1].legend(['train-loss', 'val-loss'], loc='upper left', fontsize = 14)\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T10:05:06.048689Z","iopub.status.busy":"2022-12-30T10:05:06.048340Z","iopub.status.idle":"2022-12-30T10:05:06.133868Z","shell.execute_reply":"2022-12-30T10:05:06.132951Z","shell.execute_reply.started":"2022-12-30T10:05:06.048661Z"},"trusted":true},"outputs":[],"source":["best_model = VGG16.load('./vgg16-sgd-nesterov-mnist.pt').to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T10:05:06.697180Z","iopub.status.busy":"2022-12-30T10:05:06.696522Z","iopub.status.idle":"2022-12-30T10:05:09.330172Z","shell.execute_reply":"2022-12-30T10:05:09.329204Z","shell.execute_reply.started":"2022-12-30T10:05:06.697140Z"},"trusted":true},"outputs":[],"source":["best_model.eval()\n","test_iterator = tqdm(test_loader, leave=True)\n","running_test_loss, running_test_acc = 0.0, 0.0\n","for tidx, (test_images, test_labels) in enumerate(test_iterator):\n","    with torch.no_grad():\n","        test_images = test_images.to(device)\n","        test_labels = test_labels.to(device)\n","\n","        test_outputs = best_model(test_images)\n","        test_loss = criterion(test_outputs, test_labels)\n","        test_acc = ((test_outputs.argmax(dim=1) == test_labels).float().mean())\n","\n","        running_test_loss += test_loss.item()\n","        running_test_acc += test_acc.item()\n","\n","        val_iterator.set_description('(Test)')\n","        val_iterator.set_postfix(test_loss=test_loss.item(), test_acc=test_acc.item())\n","\n","total_test_acc = running_test_acc/len(test_loader)\n","total_test_loss = running_test_loss/len(test_loader)\n","\n","print(f'>> Result:\\tTest loss = {total_test_loss:.5f} \\t Test Acc = {total_test_acc:.5f}')"]}],"metadata":{"kernelspec":{"display_name":"mlds","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6 (main, Oct 24 2022, 16:07:47) [GCC 11.2.0]"},"vscode":{"interpreter":{"hash":"85bcb44eba574c0a47936c5b7bc1ac542d3063793dafd808afd17b1b395c8414"}}},"nbformat":4,"nbformat_minor":4}
